{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac3f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill rates:\n",
      "Pregnancies                 0.0\n",
      "Glucose                     0.0\n",
      "BloodPressure               0.0\n",
      "SkinThickness               0.0\n",
      "Insulin                     0.0\n",
      "BMI                         0.0\n",
      "DiabetesPedigreeFunction    0.0\n",
      "Age                         0.0\n",
      "Outcome                     0.0\n",
      "dtype: float64\n",
      "Updated dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n"
     ]
    }
   ],
   "source": [
    "#Data Science Capstone\n",
    "#Data Import and Preparation:\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('health care diabetes.csv')  # Replace 'your_dataset.csv' with the actual file path\n",
    "\n",
    "# Identify the primary key\n",
    "primary_key = 'your_primary_key_column_name'  # Replace 'your_primary_key_column_name' with the actual column name\n",
    "\n",
    "# Assess the fill rate of variables and handle missing values\n",
    "fill_rates = data.isnull().mean()  # Calculate the proportion of missing values for each variable\n",
    "missing_variables = fill_rates[fill_rates > 0].index.tolist()  # Get variables with missing values\n",
    "\n",
    "# Handle missing values (example: fill missing values with mean/median)\n",
    "for variable in missing_variables:\n",
    "    if data[variable].dtype == 'object':\n",
    "        data[variable].fillna(data[variable].mode()[0], inplace=True)  # Fill missing categorical values with mode\n",
    "    else:\n",
    "        data[variable].fillna(data[variable].median(), inplace=True)  # Fill missing numerical values with median\n",
    "\n",
    "# Print the fill rate of variables\n",
    "print(\"Fill rates:\")\n",
    "print(fill_rates)\n",
    "\n",
    "# Print the updated dataset with filled missing values\n",
    "print(\"Updated dataset:\")\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd1086af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No primary key identified.\n",
      "Columns that may require indexing: ['DiabetesPedigreeFunction']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('health care diabetes.csv')\n",
    "\n",
    "# Identify the primary key\n",
    "primary_key = None\n",
    "\n",
    "# Check for unique identifier columns\n",
    "for column in data.columns:\n",
    "    if data[column].nunique() == len(data):\n",
    "        primary_key = column\n",
    "        break\n",
    "\n",
    "if primary_key is not None:\n",
    "    print(\"Primary key identified:\", primary_key)\n",
    "else:\n",
    "    print(\"No primary key identified.\")\n",
    "\n",
    "# Assess the need for indexing\n",
    "indexing_required = []\n",
    "\n",
    "# Check for columns that may benefit from indexing\n",
    "for column in data.columns:\n",
    "    unique_values_ratio = data[column].nunique() / len(data)\n",
    "    if unique_values_ratio > 0.5:\n",
    "        indexing_required.append(column)\n",
    "\n",
    "if len(indexing_required) > 0:\n",
    "    print(\"Columns that may require indexing:\", indexing_required)\n",
    "else:\n",
    "    print(\"No columns require indexing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "913760f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill rate of variables:\n",
      "Pregnancies                 100.0\n",
      "Glucose                     100.0\n",
      "BloodPressure               100.0\n",
      "SkinThickness               100.0\n",
      "Insulin                     100.0\n",
      "BMI                         100.0\n",
      "DiabetesPedigreeFunction    100.0\n",
      "Age                         100.0\n",
      "Outcome                     100.0\n",
      "dtype: float64\n",
      "\n",
      "Missing value treatment:\n",
      "Pregnancies: Drop\n",
      "Glucose: Drop\n",
      "BloodPressure: Drop\n",
      "SkinThickness: Drop\n",
      "Insulin: Drop\n",
      "BMI: Drop\n",
      "DiabetesPedigreeFunction: Drop\n",
      "Age: Drop\n",
      "Outcome: Drop\n"
     ]
    }
   ],
   "source": [
    "#Gauge the fill rate of the variables and devise plans for missing value treatment. Please explain explicitly the reason for the treatment chosen for each variable.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import the data\n",
    "data = pd.read_csv('health care diabetes.csv')\n",
    "\n",
    "# Calculate the fill rate of variables\n",
    "fill_rate = data.count() / len(data) * 100\n",
    "\n",
    "# Print fill rate for each variable\n",
    "print(\"Fill rate of variables:\")\n",
    "print(fill_rate)\n",
    "\n",
    "# Devise plans for missing value treatment\n",
    "missing_value_treatment = {}\n",
    "\n",
    "# Analyze the fill rate and choose appropriate treatment for each variable\n",
    "for column in data.columns:\n",
    "    if fill_rate[column] >= 90:\n",
    "        # If fill rate is high (>=90%), we can consider dropping the column\n",
    "        missing_value_treatment[column] = \"Drop\"\n",
    "    elif fill_rate[column] >= 50:\n",
    "        # If fill rate is moderate (>=50%), we can consider imputing missing values with mean or median\n",
    "        missing_value_treatment[column] = \"Impute with mean/median\"\n",
    "    else:\n",
    "        # If fill rate is low (<50%), we may need to analyze further or drop the column\n",
    "        missing_value_treatment[column] = \"Further analysis or drop\"\n",
    "\n",
    "# Print missing value treatment for each variable\n",
    "print(\"\\nMissing value treatment:\")\n",
    "for column, treatment in missing_value_treatment.items():\n",
    "    print(f\"{column}: {treatment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b27e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('health care diabetes.csv')\n",
    "\n",
    "# Separate the features (X) and the target variable (y)\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "726153cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PercentOwnership'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PercentOwnership'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7432\\3677465621.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Filter locations where percent ownership is above 10% and percent of households with a second mortgage is below 50%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfiltered_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PercentOwnership'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SecondMortgage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Sort the data by percentage of households with a second mortgage in descending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3629\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3631\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3632\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3633\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PercentOwnership'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data from the \"health care diabetes.csv\" file\n",
    "data = pd.read_csv('health care diabetes.csv')\n",
    "\n",
    "# Filter locations where percent ownership is above 10% and percent of households with a second mortgage is below 50%\n",
    "filtered_data = data[(data['PercentOwnership'] > 10) & (data['SecondMortgage'] < 50)]\n",
    "\n",
    "# Sort the data by percentage of households with a second mortgage in descending order\n",
    "sorted_data = filtered_data.sort_values('SecondMortgage', ascending=False).head(2500)\n",
    "\n",
    "# Visualize the top 2,500 locations on a geo-map\n",
    "# Use latitude and longitude columns to plot the locations on a map\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=sorted_data, x='Longitude', y='Latitude', hue='SecondMortgage', size='PercentOwnership', alpha=0.8)\n",
    "plt.title('Locations with High Second Mortgage Percentage')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()\n",
    "\n",
    "# Calculate bad debt\n",
    "sorted_data['BadDebt'] = sorted_data['SecondMortgage'] + sorted_data['HomeEquity'] - sorted_data['HomeEquitySecondMortgage']\n",
    "\n",
    "# Pie chart for overall debt\n",
    "plt.figure(figsize=(8, 6))\n",
    "sorted_data[['SecondMortgage', 'HomeEquity', 'BadDebt']].sum().plot(kind='pie', autopct='%1.1f%%', labels=None)\n",
    "plt.title('Overall Debt')\n",
    "plt.legend(labels=['Second Mortgage', 'Home Equity', 'Bad Debt'])\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for bad debt\n",
    "plt.figure(figsize=(6, 6))\n",
    "sorted_data[['BadDebt']].sum().plot(kind='pie', autopct='%1.1f%%', labels=None)\n",
    "plt.title('Bad Debt')\n",
    "plt.legend(labels=['Bad Debt'])\n",
    "plt.show()\n",
    "\n",
    "# Box and whisker plot for different debt types in different cities\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(data=sorted_data, x='City', y=['SecondMortgage', 'HomeEquity', 'GoodDebt', 'BadDebt'])\n",
    "plt.title('Debt Types in Different Cities')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Debt Amount')\n",
    "plt.show()\n",
    "\n",
    "# Collated income distribution chart\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.kdeplot(data=sorted_data, x='FamilyIncome', shade=True)\n",
    "sns.kdeplot(data=sorted_data, x='HouseholdIncome', shade=True)\n",
    "sns.kdeplot(data=sorted_data, x='RemainingIncome', shade=True)\n",
    "plt.title('Income Distribution')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(labels=['Family Income', 'Household Income', 'Remaining Income'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76951d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
